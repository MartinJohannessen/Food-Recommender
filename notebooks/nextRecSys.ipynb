{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMJ_data_all__b_new = pd.read_csv('../input/BMJ-data-all--b-new.csv', sep='\\t')\n",
    "item_profiles1 = pd.read_csv('../input/item-profiles1.csv', sep=';')\n",
    "item_profiles2 = pd.read_csv('../input/item-profiles2.csv', sep=';')\n",
    "item_profiles3 = pd.read_csv('../input/item-profiles3.csv', sep=';')\n",
    "ratings = pd.read_csv('../input/user-item-rating.csv', sep='\\t', names=['user_id','item_id','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use an inner joint on the column 'Recipe ID' to join the datasets toghether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_profiles = item_profiles1.set_index('Recipe ID').join(item_profiles2.set_index('Recipe ID'), how= 'inner')#.join(item_profiles3.set_index('Recipe ID'), how= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use this healthiness method to calculate the healthiness of recipes, and to set weights for the post filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def healthiness(itemsDataframe):\n",
    "    \n",
    "    # Calculate the energy percentage of each relevant macronutrient. 1g of fat contains 9 kCal. \n",
    "    fat = ((itemsDataframe['Fat (g)'] * 9) / itemsDataframe['Calories (kCal)']) * 100\n",
    "    sugar = ((itemsDataframe['Sugar (g)'] * 4) / itemsDataframe['Calories (kCal)']) * 100\n",
    "    saturatedFat = ((itemsDataframe['Saturated Fat (g)'] * 9) / itemsDataframe['Calories (kCal)']) * 100\n",
    "    \n",
    "    # This calculates a continous version of the healthiness score. Fat/3 because the recommended limit for fat is 3X the others.\n",
    "    itemsDataframe['Unhealtiness'] = (fat / 3) + sugar + saturatedFat\n",
    "    \n",
    "    # These are bounderies and points are tunable to influence \n",
    "    # post filter weights in accordence with the health recommendations.\n",
    "    itemsDataframe.loc[fat > 30, 'fatPoints'] = 0\n",
    "    itemsDataframe.loc[fat >= 40, 'fatPoints'] = -1\n",
    "    itemsDataframe.loc[fat >= 50, 'fatPoints'] = -2\n",
    "    itemsDataframe.loc[fat >= 60, 'fatPoints'] = -3\n",
    "    itemsDataframe.loc[fat >= 70, 'fatPoints'] = -4\n",
    "    itemsDataframe.loc[fat >= 80, 'fatPoints'] = -5\n",
    "    itemsDataframe.loc[fat <= 30, 'fatPoints'] = 1 \n",
    "    itemsDataframe.loc[fat <= 20, 'fatPoints'] = 2\n",
    "    itemsDataframe.loc[fat <= 10, 'fatPoints'] = 3\n",
    "    itemsDataframe.loc[fat <= 5, 'fatPoints'] = 4 \n",
    "    itemsDataframe.loc[fat <= 1, 'fatPoints'] = 5\n",
    "\n",
    "    itemsDataframe.loc[sugar > 10, 'sugarPoints'] = 0\n",
    "    itemsDataframe.loc[sugar >= 13, 'sugarPoints'] = -1\n",
    "    itemsDataframe.loc[sugar >= 16, 'sugarPoints'] = -2\n",
    "    itemsDataframe.loc[sugar >= 19, 'sugarPoints'] = -3\n",
    "    itemsDataframe.loc[sugar >= 22, 'sugarPoints'] = -4\n",
    "    itemsDataframe.loc[sugar >= 25, 'sugarPoints'] = -5\n",
    "    itemsDataframe.loc[sugar <= 10, 'sugarPoints'] = 1 \n",
    "    itemsDataframe.loc[sugar <= 7, 'sugarPoints'] = 2\n",
    "    itemsDataframe.loc[sugar <= 5, 'sugarPoints'] = 3 \n",
    "    itemsDataframe.loc[sugar <= 3, 'sugarPoints'] = 4\n",
    "    itemsDataframe.loc[sugar <= 1, 'sugarPoints'] = 5 \n",
    "        \n",
    "    itemsDataframe.loc[saturatedFat > 10, 'satFatPoints'] = 0\n",
    "    itemsDataframe.loc[saturatedFat >= 13, 'satFatPoints'] = -1\n",
    "    itemsDataframe.loc[saturatedFat >= 16, 'satFatPoints'] = -2\n",
    "    itemsDataframe.loc[saturatedFat >= 19, 'satFatPoints'] = -3\n",
    "    itemsDataframe.loc[saturatedFat >= 22, 'satFatPoints'] = -4\n",
    "    itemsDataframe.loc[saturatedFat >= 25, 'satFatPoints'] = -5\n",
    "    itemsDataframe.loc[saturatedFat <= 10, 'satFatPoints'] = 1 \n",
    "    itemsDataframe.loc[saturatedFat <= 7, 'satFatPoints'] = 2\n",
    "    itemsDataframe.loc[saturatedFat <= 5, 'satFatPoints'] = 3 \n",
    "    itemsDataframe.loc[saturatedFat <= 3, 'satFatPoints'] = 4\n",
    "    itemsDataframe.loc[saturatedFat <= 1, 'satFatPoints'] = 5 \n",
    "        \n",
    "       \n",
    "    itemsDataframe['Healthiness'] = itemsDataframe['fatPoints'] + itemsDataframe['satFatPoints'] + itemsDataframe['sugarPoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply healthiness evaluation to each recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthiness(item_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evaluations_at_k(predictions):\n",
    "\n",
    "    # K is the number of highest ranking predictions to consider\n",
    "    k = 10\n",
    "    # This is the threshold for what is considered an adequate recommendation.\n",
    "    threshold = 3.5\n",
    "    \n",
    "    # We map the predictions to the users. uid=user identity, iid=item identity, true_r[ating], est[imated rating]. \n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and retrieve the k highest ones and put them in a dictionary.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:k]\n",
    "        \n",
    "    # Remove the dictionary entries that didn't have enough ratings because of the data partitioning. \n",
    "    top_k = top_n.copy()\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        if (len(top_k[uid]) != 10):\n",
    "            top_n.pop(uid)\n",
    "            \n",
    "    # Calculate the healthiness average of all recommendations. \n",
    "    # 0 = the tipping point between inside and outside of HDR recommendations. Negative value means unhealthy.\n",
    "    healthinessAverage = 0\n",
    "    count = 0\n",
    "    for x in top_k.items():\n",
    "        count =  count + 1\n",
    "        healthiness = 0\n",
    "        for y in x[1]:\n",
    "            healthiness = healthiness + item_profiles.at[y[0], 'Healthiness']\n",
    "        healthinessAverage = healthinessAverage + (healthiness/10)\n",
    "    \n",
    "    healthinessAverage = healthinessAverage/count\n",
    "    \n",
    "    # This time we put put the estimated rating and the true rating in the dictionary.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        \n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        \n",
    "    # Extract relevant lists from the named tuples in predictions, and calculate NDCG.\n",
    "    predictions_list = [[x[3] for x in predictions]]\n",
    "    true_scores = [[x[2] for x in predictions]]\n",
    "    ndcg = ndcg_score(true_scores, predictions_list, k)\n",
    "    \n",
    "    # Calculate the averages of precision and recall\n",
    "    precision = (sum(prec for prec in precisions.values())) / len(precisions)\n",
    "    recall = (sum(rec for rec in recalls.values())) / len(recalls)\n",
    "    \n",
    "    \n",
    "    return precision, recall, ndcg, healthinessAverage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\recommender\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8767589778228068 Recall: 0.9276022584837479 NDCG_score: 0.9727272727272726 Healthiness: -0.5209613869188338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\recommender\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.874304303740423 Recall: 0.921780608494392 NDCG_score: 0.9705685618729094 Healthiness: -0.442271293375394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\recommender\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.876878202724658 Recall: 0.9250915600890505 NDCG_score: 0.9749999999999998 Healthiness: -0.43787401574803114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\recommender\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8776985379787269 Recall: 0.924635545749972 NDCG_score: 0.9715254237288133 Healthiness: -0.5101815311760063\n",
      "Precision: 0.8750165604299452 Recall: 0.9193087177681339 NDCG_score: 0.9702005730659025 Healthiness: -0.45188976377952594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\recommender\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "#Define a Reader object\n",
    "#The Reader object helps in parsing the file or dataframe containing ratings\n",
    "reader = Reader()\n",
    "\n",
    "#Create the dataset to be used for building the filter\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "# The algoritm to be used, SVD.\n",
    "svd = SVD()\n",
    "\n",
    "# We use 5 fold cross evaluation.\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Run the algorithm 5 times and evaluate.\n",
    "for trainset, testset in kf.split(data):\n",
    "    svd.fit(trainset)\n",
    "    predictions = svd.test(testset)\n",
    "    precision, recall, ndcg, healthinessAverage = evaluations_at_k(predictions)\n",
    "    \n",
    "    print(\"Precision:\", precision, \"Recall:\", recall, \"NDCG_score:\", ndcg, \"Healthiness:\", healthinessAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the post filter method. Suprise predictions are given in a list of immutable tuples.\n",
    "# To post filter the predictions we make a dataframe of the predictions list, change the predictions,\n",
    "# and make a new list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def postfilter(predictions, healthinessFactor):\n",
    "    predictionsDF = pd.DataFrame.from_records(predictions, columns=['uid', 'iid', 'r_ui', 'est', 'details'])\n",
    "    ratingsProcessed = predictionsDF.copy()\n",
    "    ratingsProcessed = ratingsProcessed.join(item_profiles['Healthiness'], how= 'inner', on= 'iid', sort=False)\n",
    "    # This is were the values are transformed based on the healthinessFactor constructor and the health points of the recipes.\n",
    "    ratingsProcessed['est'] = ratingsProcessed['est'] + (ratingsProcessed['Healthiness']*healthinessFactor)\n",
    "    ratingsProcessed.drop(labels='Healthiness', axis=1, inplace=True)\n",
    "    ratingsProcessed = list(ratingsProcessed.itertuples(name='Prediction', index=False))\n",
    "    return ratingsProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the algoritm again, but this time we use post filtering and automatic tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 5, 'lr_all': 0.01, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "# there is a trade off between NDCG score and recall. Tuning the parameters may increase one and lower the other.\n",
    "param_grid = {'n_epochs': [5,5], 'lr_all': [0.01, 0.1], 'reg_all':[0.01,0.1]}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_params['rmse'])\n",
    "svd = grid_search.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "precisionAvg = 0\n",
    "recallAvg = 0\n",
    "ndcgAvg = 0\n",
    "healthinessAvg = 0\n",
    "for trainset, testset in kf.split(data):\n",
    "    svd.fit(trainset)\n",
    "    # The second parameter is the post fileter healthiness factor.\n",
    "    predictions = postfilter(svd.test(testset), 0.1)\n",
    "    precision, recall, ndcg, healthinessAverage = evaluations_at_k(predictions)\n",
    "    precisionAvg = precisionAvg + precision\n",
    "    recallAvg = recallAvg + recall\n",
    "    ndcgAvg = ndcgAvg + ndcg\n",
    "    healthinessAvg = healthinessAvg + healthinessAverage\n",
    "    \n",
    "print(\"Precision:\", precisionAvg/5, \"Recall:\", recallAvg/5, \"NDCG_score:\", ndcgAvg/5, \"Healthiness:\", healthinessAvg/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision: 0.8712420729999429 Recall: 0.9178423083126048 NDCG_score: 0.9377159117569617 Healthiness: -0.039079338783746434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
